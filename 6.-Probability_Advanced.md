Probability\_Advanced
================
Antonio Dagnino Mendez
7/8/2021

### Import Libraries

``` r
library(dplyr)
```

    ## Warning: package 'dplyr' was built under R version 4.0.4

    ## 
    ## Attaching package: 'dplyr'

    ## The following objects are masked from 'package:stats':
    ## 
    ##     filter, lag

    ## The following objects are masked from 'package:base':
    ## 
    ##     intersect, setdiff, setequal, union

``` r
library(ggplot2)
```

    ## Warning: package 'ggplot2' was built under R version 4.0.5

``` r
library(ggthemes)
```

    ## Warning: package 'ggthemes' was built under R version 4.0.4

``` r
library(GGally)
```

    ## Warning: package 'GGally' was built under R version 4.0.5

    ## Registered S3 method overwritten by 'GGally':
    ##   method from   
    ##   +.gg   ggplot2

### T-test: One-Sample

``` r
#H0: sample mean == 0
#Ha: sample mean != 0
#Result: p-value is 0.2283 (Fail to reject)
# Meaning that x mean is equal to the input mean in t test

set.seed(1)
x <- rnorm(100,mean=22,sd=1)
t.test(x, mu=22, alternative = "two.sided", var.equal=T)
```

    ## 
    ##  One Sample t-test
    ## 
    ## data:  x
    ## t = 1.2123, df = 99, p-value = 0.2283
    ## alternative hypothesis: true mean is not equal to 22
    ## 95 percent confidence interval:
    ##  21.93067 22.28711
    ## sample estimates:
    ## mean of x 
    ##  22.10889

### T-Test: Two independent samples (Welch)

``` r
# H0: x mean => y mean
# Ha: x mean < y mean
# Result: Reject Null hypothesis
#Meaning there is statistical significance that x mean is lower than y

y <- rnorm(100,mean=100,sd=1)

t.test(x,y,alternative="less", paired=F, var.equal = F)
```

    ## 
    ##  Welch Two Sample t-test
    ## 
    ## data:  x and y
    ## t = -592.89, df = 197.19, p-value < 2.2e-16
    ## alternative hypothesis: true difference in means is less than 0
    ## 95 percent confidence interval:
    ##      -Inf -77.6363
    ## sample estimates:
    ## mean of x mean of y 
    ##  22.10889  99.96219

### T-Test: Two dependent samples (paired)

``` r
#H0: mean x == mean y
#Ha: mean x != mean y
#Notice degrees of freedom value is 99 since it's a paired test
#Result: Reject null hypothesis meaning the means are different

t.test(x,y,alternative="two.sided", paired=T, var.equal = T)
```

    ## 
    ##  Paired t-test
    ## 
    ## data:  x and y
    ## t = -592.59, df = 99, p-value < 2.2e-16
    ## alternative hypothesis: true difference in means is not equal to 0
    ## 95 percent confidence interval:
    ##  -78.11399 -77.59262
    ## sample estimates:
    ## mean of the differences 
    ##                -77.8533

### ANOVA: One-way

``` r
group1 = c(18.2, 20.1, 17.6, 16.8, 18.8, 19.7, 19.1)
group2 = c(17.4, 18.7, 19.1, 16.4, 15.9, 18.4, 17.7)
group3 = c(15.2, 18.8, 17.7, 16.5, 15.9, 17.1, 16.7)

cbind("Mean1"=mean(group1),"Mean2"=mean(group2),"Mean3"=mean(group3))
```

    ##         Mean1    Mean2    Mean3
    ## [1,] 18.61429 17.65714 16.84286

``` r
print('--- ---')
```

    ## [1] "--- ---"

``` r
group_numbers <- as.factor(rep(x=1:3, times=rep(7, 3)))

data_groups <- data.frame(
  "observations"= c(group1, group2, group3),
  "Group_number"=group_numbers
                        )

summary(aov(observations ~ Group_number, data=data_groups))
```

    ##              Df Sum Sq Mean Sq F value Pr(>F)  
    ## Group_number  2  11.01   5.503   3.968 0.0373 *
    ## Residuals    18  24.96   1.387                 
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

``` r
#H0: No Difference between means (mean group1 == mean group2 == mean group3)  USE THIS IF YOU FAIL TO REJECT
#Ha: There is difference between means USE THIS IF YOU REJECT
#Since the p-value is less than 0.05, we reject the null hypothesis. We conclude that there
#is significant difference among the means of these three groups.
```

### ANOVA: Two-way

``` r
#Get the Data
my_data <- ToothGrowth
my_data$dose <- factor(my_data$dose, 
                  levels = c(0.5, 1, 2),
                  labels = c("D0.5", "D1", "D2"))
set.seed(1234)
dplyr::slice_sample(my_data, n=10)
```

    ##     len supp dose
    ## 1  21.5   VC   D2
    ## 2  17.3   VC   D1
    ## 3  27.3   OJ   D2
    ## 4  18.5   VC   D2
    ## 5   8.2   OJ D0.5
    ## 6  26.4   OJ   D1
    ## 7  25.8   OJ   D1
    ## 8   5.2   VC D0.5
    ## 9   6.4   VC D0.5
    ## 10  9.4   OJ D0.5

``` r
table(my_data$supp, my_data$dose) # Count per category and group
```

    ##     
    ##      D0.5 D1 D2
    ##   OJ   10 10 10
    ##   VC   10 10 10

``` r
#-------------------------------------------

summary(aov(len ~ supp + dose + supp:dose, data = my_data))
```

    ##             Df Sum Sq Mean Sq F value   Pr(>F)    
    ## supp         1  205.4   205.4  15.572 0.000231 ***
    ## dose         2 2426.4  1213.2  92.000  < 2e-16 ***
    ## supp:dose    2  108.3    54.2   4.107 0.021860 *  
    ## Residuals   54  712.1    13.2                     
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

``` r
#Ho: no difference between means... USE THIS IF FAIL TO REJECT
#Ha: significant difference between means... USE THIS IF REJECT
# Result: For both groups, we reject the hypothesis. In other words, there is a significant difference in means

#From the ANOVA results, you can conclude the following, based on the p-values and a significance level of 0.05:
#the p-value of supp is 0.000429 (significant), which indicates that the levels of supp are associated with significant different tooth length.
#the p-value of dose is < 2e-16 (significant), which indicates that the levels of dose are associated with significant different tooth length.
#the p-value for the interaction between supp*dose is 0.02 (significant), which indicates that the relationships between dose and tooth length depends on the supp method.
```

### Chi Square: goodness of fit

``` r
tulip <- c(81, 50, 27)
res <- chisq.test(tulip, p = c(1/2, 1/3, 1/6))
res
```

    ## 
    ##  Chi-squared test for given probabilities
    ## 
    ## data:  tulip
    ## X-squared = 0.20253, df = 2, p-value = 0.9037

``` r
res$p.value
```

    ## [1] 0.9036928

``` r
res$p.estimate
```

    ## NULL

### Chi Square: Test of Independence

``` r
#Get Data
file_path <- "http://www.sthda.com/sthda/RDoc/data/housetasks.txt"
housetasks <- read.delim(file_path, row.names = 1)

#---------


chisq <- chisq.test(housetasks)
chisq
```

    ## 
    ##  Pearson's Chi-squared test
    ## 
    ## data:  housetasks
    ## X-squared = 1944.5, df = 36, p-value < 2.2e-16

``` r
#Null hypothesis (H0): the row and the column variables of the contingency table are independent.
#Alternative hypothesis (H1): row and column variables are dependent
# Result In our example, the row and the column variables are statistically significantly associated (p-value = 0)
chisq$observed
```

    ##            Wife Alternating Husband Jointly
    ## Laundry     156          14       2       4
    ## Main_meal   124          20       5       4
    ## Dinner       77          11       7      13
    ## Breakfeast   82          36      15       7
    ## Tidying      53          11       1      57
    ## Dishes       32          24       4      53
    ## Shopping     33          23       9      55
    ## Official     12          46      23      15
    ## Driving      10          51      75       3
    ## Finances     13          13      21      66
    ## Insurance     8           1      53      77
    ## Repairs       0           3     160       2
    ## Holidays      0           1       6     153

``` r
round(chisq$expected,2)
```

    ##             Wife Alternating Husband Jointly
    ## Laundry    60.55       25.63   38.45   51.37
    ## Main_meal  52.64       22.28   33.42   44.65
    ## Dinner     37.16       15.73   23.59   31.52
    ## Breakfeast 48.17       20.39   30.58   40.86
    ## Tidying    41.97       17.77   26.65   35.61
    ## Dishes     38.88       16.46   24.69   32.98
    ## Shopping   41.28       17.48   26.22   35.02
    ## Official   33.03       13.98   20.97   28.02
    ## Driving    47.82       20.24   30.37   40.57
    ## Finances   38.88       16.46   24.69   32.98
    ## Insurance  47.82       20.24   30.37   40.57
    ## Repairs    56.77       24.03   36.05   48.16
    ## Holidays   55.05       23.30   34.95   46.70

``` r
chisq$p.value
```

    ## [1] 0

``` r
chisq$estimate
```

    ## NULL

### Wilcoxon Test: One-sample test

``` r
set.seed(1)
x <- round(rnorm(100,mean=22,sd=1),1)
wilcox.test(x, mu =22, alternative = "two.sided")
```

    ## 
    ##  Wilcoxon signed rank test with continuity correction
    ## 
    ## data:  x
    ## V = 2643, p-value = 0.1781
    ## alternative hypothesis: true location is not equal to 22

``` r
summary(x)
```

    ##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
    ##   19.80   21.50   22.15   22.11   22.70   24.40

``` r
#H0: Same
#Ha: Different
```

### Wilcoxon Test: Rank Sum

``` r
#Variable x is a normally distributed sample
# Variable y is a skewed distributed sample
set.seed(1)
x <- round(rnorm(100,mean=0,sd=1),1)
set.seed(2)
y <- round(fGarch::rsnorm(100,mean=0,sd=1,xi=1.5),1)

wilcox.test(x,y,alternative = "two.sided",paired = F)
```

    ## 
    ##  Wilcoxon rank sum test with continuity correction
    ## 
    ## data:  x and y
    ## W = 5299, p-value = 0.4655
    ## alternative hypothesis: true location shift is not equal to 0

``` r
#H0: Distributions are equal
#Ha: Distributions are different
#Result: p value is more than 0.05, meaning that distributions are equal (H0 stays)
#Although distributions are different, they both have same statistics !!!!!!!!!!!!!!!!!!!
#therefore, wilcoxon test flags the samples as equal
```

### Wilcoxon Test: Signed

``` r
#Variable x is a normally distributed sample
#Variable y is a normallu distributed sample with different mean
set.seed(1)
x <- round(rnorm(100,mean=0,sd=1),1)
set.seed(2)
y <- round(rnorm(100,mean=10,sd=1),1)

wilcox.test(x,y,alternative = "two.sided",paired = F)
```

    ## 
    ##  Wilcoxon rank sum test with continuity correction
    ## 
    ## data:  x and y
    ## W = 0, p-value < 2.2e-16
    ## alternative hypothesis: true location shift is not equal to 0

``` r
#H0: Distributions are equal
#Ha: Distributions are different
#Result: p value is less than 0.05, meaning that distributions are same (Ha stays)
```

### Kruskal-Wallis H Test

``` r
"
The airquality dataset contains the daily air quality measurements in New York, from
May to September 1973. Without assuming the data to have normal distribution, test at
Î± = 0:05 significance level if the monthly ozone density in New York has identical data
distributions from May to September 1973.
"
```

    ## [1] "\nThe airquality dataset contains the daily air quality measurements in New York, from\nMay to September 1973. Without assuming the data to have normal distribution, test at\na = 0:05 significance level if the monthly ozone density in New York has identical data\ndistributions from May to September 1973.\n"

``` r
head(airquality)
```

    ##   Ozone Solar.R Wind Temp Month Day
    ## 1    41     190  7.4   67     5   1
    ## 2    36     118  8.0   72     5   2
    ## 3    12     149 12.6   74     5   3
    ## 4    18     313 11.5   62     5   4
    ## 5    NA      NA 14.3   56     5   5
    ## 6    28      NA 14.9   66     5   6

``` r
kruskal.test(Ozone ~ Month, data = airquality)
```

    ## 
    ##  Kruskal-Wallis rank sum test
    ## 
    ## data:  Ozone by Month
    ## Kruskal-Wallis chi-squared = 29.267, df = 4, p-value = 6.901e-06

``` r
#Since the p-value is less than 0.05, we conclude that there is a significant difference among
#the monthly ozone density levels in New York.
```

### Friedman Test

``` r
"
A data science student is using three machine learning algorithms to analyze a given
dataset. She tests her model first with a Decision Tree, secondly with a Logistic Regression and then with a Naive Bayes algorithm. She uses 10-fold Cross Validation for each
model. With this method, she randomly divides her dataset into 10 parts and uses 9 of
those parts for training and reserves one tenth for testing. She repeats this procedure
10 times, each time reserving a different tenth-part for testing. Although the cross validation uses different test sets for each run, she makes sure that the three algorithms get
the same test set. Then, she records the Accuracy for each fold. The accuracy for each
fold of the algorithms are given as follows:
"
```

    ## [1] "\nA data science student is using three machine learning algorithms to analyze a given\ndataset. She tests her model first with a Decision Tree, secondly with a Logistic Regression and then with a Naive Bayes algorithm. She uses 10-fold Cross Validation for each\nmodel. With this method, she randomly divides her dataset into 10 parts and uses 9 of\nthose parts for training and reserves one tenth for testing. She repeats this procedure\n10 times, each time reserving a different tenth-part for testing. Although the cross validation uses different test sets for each run, she makes sure that the three algorithms get\nthe same test set. Then, she records the Accuracy for each fold. The accuracy for each\nfold of the algorithms are given as follows:\n"

``` r
DT<-c(75, 79, 69, 78, 65, 87, 74, 81, 77, 85)
LR<-c(85, 68, 78, 73, 69, 76, 69, 80, 73, 67)
NB<-c(86, 75, 79, 82, 68, 69, 77, 81, 80, 79)
Accuracy <- c(DT,LR,NB)
Testnames<- rep(c('DT','LR', 'NB'), each=10, rep =3)
Folds <- as.factor(rep(c(1:10), 3))
data.frame(Accuracy,Testnames,Folds)
```

    ##    Accuracy Testnames Folds
    ## 1        75        DT     1
    ## 2        79        DT     2
    ## 3        69        DT     3
    ## 4        78        DT     4
    ## 5        65        DT     5
    ## 6        87        DT     6
    ## 7        74        DT     7
    ## 8        81        DT     8
    ## 9        77        DT     9
    ## 10       85        DT    10
    ## 11       85        LR     1
    ## 12       68        LR     2
    ## 13       78        LR     3
    ## 14       73        LR     4
    ## 15       69        LR     5
    ## 16       76        LR     6
    ## 17       69        LR     7
    ## 18       80        LR     8
    ## 19       73        LR     9
    ## 20       67        LR    10
    ## 21       86        NB     1
    ## 22       75        NB     2
    ## 23       79        NB     3
    ## 24       82        NB     4
    ## 25       68        NB     5
    ## 26       69        NB     6
    ## 27       77        NB     7
    ## 28       81        NB     8
    ## 29       80        NB     9
    ## 30       79        NB    10

``` r
friedman.test(Accuracy, Testnames, Folds)
```

    ## 
    ##  Friedman rank sum test
    ## 
    ## data:  Accuracy, Testnames and Folds
    ## Friedman chi-squared = 4.6667, df = 2, p-value = 0.09697

``` r
#The p-value is greater than 0.05. We cannot suggest that any of these algorithms is
#significantly better in accuracy compared to the others apart from the effect of Folds.
```
